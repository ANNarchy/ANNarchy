{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar Learning problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the bar learning problem is located in the\n",
    "`examples/bar_learning` folder. The bar learning problem describes the\n",
    "process of learning receptive fields on an artificial input pattern.\n",
    "Images consisting of independent bars are used. Those images are\n",
    "generated as following: an 8\\*8 image can filled randomly by eight\n",
    "horizontal or vertical bars, with a probability of 1/8 for each.\n",
    "\n",
    "These input images are fed into a neural population, whose neurons\n",
    "should learn to extract the independent components of the input\n",
    "distribution, namely single horizontal or vertical bars.\n",
    "\n",
    "If you have `pyqtgraph` installed, you can simply try the network by\n",
    "typing:\n",
    "\n",
    "~~~\n",
    "python BarLearning.py\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model consists of two populations `Input` and `Feature`. The size of\n",
    "`Input` should be chosen to fit the input image size (here 8\\*8). The\n",
    "number of neurons in the `Feature` population should be higher than the\n",
    "total number of independent bars (16, we choose here 32 neurons). The\n",
    "`Feature` population gets excitory connections from `Input` through an\n",
    "all-to-all connection pattern. The same pattern is used for the\n",
    "inhibitory connections within `Feature`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the neurons and populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANNarchy 4.6 (4.6.0b) on linux (posix). \n"
     ]
    }
   ],
   "source": [
    "from ANNarchy import *\n",
    "\n",
    "#setup(paradigm=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input** population:\n",
    "\n",
    "The input pattern will be clamped into this population by the main\n",
    "loop for every trial, so we need just an empty neuron at this\n",
    "point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "InputNeuron = Neuron(parameters=\"r = 0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick here is to declare `r` as a parameter, not a variable: its\n",
    "value will not be computed by the simulator, but only set by external\n",
    "input. The `Input` population can then be created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Input = Population(geometry=(8, 8), neuron=InputNeuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature** population:\n",
    "\n",
    "The neuron type composing this population sums up all the excitory\n",
    "inputs gain from `Input` and the lateral inhibition within `Feature`.\n",
    "\n",
    "$$\\tau \\frac {dr_{j}^{\\text{Feature}}}{dt} + r_{j}^{Feature} = \\sum_{i} w_{ij} \\cdot r_{i}^{\\text{Input}}  - \\sum_{k, k \\ne j} w_{kj} * r_{k}^{Feature}$$\n",
    "\n",
    "could be implemented as the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LeakyNeuron = Neuron(\n",
    "    parameters=\"\"\" \n",
    "        tau = 10.0 : population\n",
    "    \"\"\",\n",
    "    equations=\"\"\"\n",
    "        tau * dr/dt + r = sum(exc) - sum(inh) : min=0.0\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The firing rate is restricted to positive values with the `min=0.0`\n",
    "flag. The population is created in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Feature = Population(geometry=(8, 4), neuron=LeakyNeuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We give it a (8, 4) geometry for visualization only, it does not\n",
    "influence computations at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the synapse and projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both feedforward (`Input` $\\rightarrow$ `Feature`) and lateral\n",
    "(`Feature` $\\rightarrow$ `Feature`) projections are learned using the\n",
    "Oja learning rule (a regularized Hebbian learning rule ensuring the sum\n",
    "of all weights coming to a neuron is constant). Only some parameters will\n",
    "differ between the projections.\n",
    "\n",
    "$$\\tau \\frac{dw_{ij}}{dt} = r_{i} * r_{j} - \\alpha * r_{j}^{2} * w_{ij}$$\n",
    "\n",
    "where $\\alpha$ is a parameter defining the strength of the\n",
    "regularization, $r_i$ is the pre-synaptic firing rate and $r_j$ the\n",
    "post-synaptic one. The implementation of this synapse type is\n",
    "straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Oja = Synapse(\n",
    "    parameters=\"\"\" \n",
    "        tau = 2000.0 : postsynaptic\n",
    "        alpha = 8.0 : postsynaptic\n",
    "        min_w = 0.0 : postsynaptic\n",
    "    \"\"\",\n",
    "    equations=\"\"\"\n",
    "        tau * dw/dt = pre.r * post.r - alpha * post.r^2 * w : min=min_w\n",
    "    \"\"\"\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this network we need to create two projections, one excitory between\n",
    "the populations `Input` and `Feature` and one inhibitory within the\n",
    "`Feature` population itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ANNarchy.core.Projection.Projection at 0x7f977801b160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = Projection(\n",
    "    pre=Input, \n",
    "    post=Feature, \n",
    "    target='exc', \n",
    "    synapse = Oja    \n",
    ")\n",
    "ff.connect_all_to_all(weights = Uniform(-0.5, 0.5))\n",
    "                     \n",
    "lat = Projection(\n",
    "    pre=Feature, \n",
    "    post=Feature, \n",
    "    target='inh', \n",
    "    synapse = Oja\n",
    ")\n",
    "lat.connect_all_to_all(weights = Uniform(0.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two projections are all-to-all and use the `Oja` synapse type. They\n",
    "only differ by the parameter `alpha` (lower in `lat`) and\n",
    "the fact that the weights of `ff` are allowed to be negative\n",
    "(so we set the minimum value to -10.0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ff.min_w = -10.0\n",
    "lat.alpha = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the network is defined, one has to specify how inputs are fed into\n",
    "the `Input` population. A simple solution is to define a method that\n",
    "sets the firing rate of `Input` according to the specified probabilities\n",
    "every time it is called, and runs the simulation for 50 ms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trial():\n",
    "    # Reset the firing rate for all neurons\n",
    "    Input.r = 0.0\n",
    "    # Clamp horizontal bars randomly\n",
    "    for h in range(Input.geometry[0]):\n",
    "        if np.random.random() < 1.0/ float(Input.geometry[0]):\n",
    "            Input[h, :].r = 1.0\n",
    "    # Clamp vertical bars randomly\n",
    "    for w in range(Input.geometry[1]):\n",
    "        if np.random.random() < 1.0/ float(Input.geometry[1]):\n",
    "            Input[:, w].r = 1.0\n",
    "    # Simulate for 50ms\n",
    "    simulate(50.)\n",
    "    # Return firing rates and receptive fields for visualization\n",
    "    return Input.r, Feature.r, ff.receptive_fields()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can use here a single value or a Numpy array (e.g.\n",
    "`np.zeros(Input.geometry))`) to reset activity in Input, it does not matter.\n",
    "\n",
    "For all possible horizontal bars, a decision is then made whether the\n",
    "bar should appear or not, in which case the firing rate of the\n",
    "correspondng neurons is set to 1.0:\n",
    "\n",
    "``` {.python}\n",
    "    for h in range(Input.geometry[0]):\n",
    "        if np.random.random() < 1.0/ float(Input.geometry[0]):\n",
    "            Input[h, :].r = 1.0\n",
    "```\n",
    "\n",
    "`Input[h, :]` is a PopulationView, i.e. a group of neurons defined by\n",
    "the sub-indices (here the row of index `h`). Their attributes, such as\n",
    "`r`, can be accessed as if it were a regular population. The same is\n",
    "done for vertical bars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the method for setting inputs is defined, the simulation can be\n",
    "started. A basic approach would be to define an infinite loop where the\n",
    "`trial()` method is called repetitively:\n",
    "\n",
    "``` {.python}\n",
    "compile()\n",
    "\n",
    "while True:\n",
    "    trial()\n",
    "```\n",
    "\n",
    "In the file `BarLearning.py`, a visualization class using pyqtgraph is\n",
    "imported from `Viz.py`, but the user is free to use whatever method he prefers to\n",
    "visualize the result of learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling... \n",
      "OK \n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "\n",
    "    compile()\n",
    "\n",
    "    # Create and launch the GUI\n",
    "    from Viz import Viewer\n",
    "    view = Viewer(func=trial)\n",
    "    view.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
