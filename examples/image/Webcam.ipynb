{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script `examples/image/Webcam.py` applies a red filter on the input from the webcam, and isolates one mode using a dynamical neural field.\n",
    "\n",
    "Most of the concepts are similar to the Image Processing example. The `VideoPopulation` object also requires the Python bindings to OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANNarchy 4.6 (4.6.7b) on linux (posix). \n"
     ]
    }
   ],
   "source": [
    "from ANNarchy import *\n",
    "from ANNarchy.extensions.image import *\n",
    "from ANNarchy.extensions.weightsharing import SharedProjection\n",
    "clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ANNarchy.core.Projection.Projection at 0x7ff42de746d8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definition of the neurons\n",
    "LinearNeuron = Neuron(equations=\"r=sum(exc): min=0.0\")\n",
    "DNF = Neuron(parameters=\"tau=10.0\", equations=\"tau*dr/dt + r = sum(exc) + sum(inh): min=0.0, max=1.0\")\n",
    "\n",
    "# Population getting the video stream   \n",
    "width = 640\n",
    "height = 480\n",
    "video = VideoPopulation(geometry=(height, width, 3))\n",
    "\n",
    "# Subsampling population\n",
    "pooled = Population(geometry=(48, 64, 3), neuron = LinearNeuron)\n",
    "\n",
    "# Mean-pooling projection\n",
    "pool_proj = SharedProjection(pre=video, post=pooled, target='exc', operation='mean')\n",
    "pool_proj.pooling()\n",
    "\n",
    "# Define a red filter with no spatial extent\n",
    "red_filter = [[ [2.0, -1.0, -1.0] ]]\n",
    "\n",
    "# Create a population of DNF neurons downscaling the image with a factor 10 \n",
    "dnf = Population(geometry=(48, 64), neuron = DNF)\n",
    "\n",
    "# Create the convolution usinf the red filter\n",
    "ff = SharedProjection(pre=pooled, post=dnf, target='exc')\n",
    "ff.convolve(weights=red_filter, method='filter')\n",
    "\n",
    "# Create difference of Gaussians lateral connections for denoising/competition\n",
    "lat = Projection(pre=dnf, post=dnf, target='inh')\n",
    "lat.connect_dog(amp_pos=0.2, sigma_pos=0.1, amp_neg=0.1, sigma_neg=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `VideoPopulation` acquires images from the webcam: here the webcam should be able to deliver 640x480 colored images.\n",
    "\n",
    "The corresponding population is then subsampled with a factor 10, and a red filter is applied on it. This feeds a DNF (see the Neural Field\" example) which selects the region with the highest density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: unrecognized arguments: ['-f', '/run/user/1000/jupyter/kernel-2f1d5801-50bd-42de-8835-76afd8bc4945.json'] \n",
      "Compiling... \n",
      "OK \n"
     ]
    }
   ],
   "source": [
    "compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start the camera 0 (`/dev/video0`, adapt it to your machine):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video.start_camera(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple GUI based on PyQtGraph allows to display the input and output of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from pyqtgraph.Qt import QtGui, QtCore\n",
    "    import pyqtgraph as pg\n",
    "except:\n",
    "    print('PyQtGraph is not installed, can not visualize the network.')\n",
    "    exit(0)\n",
    "\n",
    "# Wrapping class    \n",
    "class Viewer(object):\n",
    "    \" Class to visualize the network activity using PyQtGraph.\"\n",
    "    \n",
    "    def __init__(self, video, result):\n",
    "        self.video = video\n",
    "        self.result = result\n",
    "        app = pg.mkQApp()\n",
    "        self.win = pg.GraphicsWindow(title=\"Live webcam\")\n",
    "        self.win.resize(640,480)   \n",
    "\n",
    "        box = self.win.addViewBox(lockAspect=True)\n",
    "        box.invertY()\n",
    "        self.vis = pg.ImageItem()\n",
    "        box.addItem(self.vis)  \n",
    "             \n",
    "        box = self.win.addViewBox(lockAspect=True)\n",
    "        box.invertY()\n",
    "        self.res = pg.ImageItem()\n",
    "        box.addItem(self.res)  \n",
    "\n",
    "        self.win.show()\n",
    "        \n",
    "        self.lastUpdate = pg.ptime.time()\n",
    "        self.avgFps = 0.0\n",
    "        \n",
    "\n",
    "    def update(self):\n",
    "        # Set the input\n",
    "        self.video.grab_image()\n",
    "        # Simulate for 10 ms with a new input\n",
    "        simulate(5.0)\n",
    "        # Refresh the GUI\n",
    "        self.vis.setImage(np.swapaxes(self.video.r,0,1))\n",
    "        self.res.setImage(np.swapaxes(self.result.r,0,1))\n",
    "        # Listen to mouse/keyboard events\n",
    "        QtGui.QApplication.processEvents()\n",
    "        # FPS\n",
    "        now = pg.ptime.time()\n",
    "        fps = 1.0 / (now - self.lastUpdate)\n",
    "        self.lastUpdate = now\n",
    "        self.avgFps = self.avgFps * 0.8 + fps * 0.2\n",
    "        # print(self.avgFps)\n",
    "        \n",
    "    def run(self):\n",
    "        \n",
    "        timer = QtCore.QTimer()\n",
    "        timer.timeout.connect(self.update)\n",
    "        timer.start(0)  \n",
    "        QtGui.QApplication.instance().exec_() \n",
    "        timer.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start the GUI\n",
    "view = Viewer(video, dnf)\n",
    "view.run() \n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
